# compress_VLMs


## BACKGROUND

This is my undergraduate graduation project.

I spent my final year of my undergraduate studies at NUS (National University of Singapore) and completed my graduation project under the guidance of [Wang Xinchao](https://cde.nus.edu.sg/ece/staff/wang-xinchao/). The topic is "Compress the visual language models". 



## SETUP

Here are some ideas from my senior [Gongfan Fang](https://fangggf.github.io/), he is the direct supervisor of my graduation project, I am very grateful to him.

1. Inspired by [LLaVA](https://github.com/haotian-liu/LLaVA), We use [Sheared-LLaMA](https://github.com/princeton-nlp/LLM-Shearing) instead of the original language model.
1. I finish the pretrain and finetune code in LLaVA file.
